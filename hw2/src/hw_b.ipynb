{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2csauEkooXD2"
   },
   "source": [
    "## B. Neural Network: MultiClass Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkgI-4O83FWC"
   },
   "source": [
    "Modify the previous architecture to model multi-class classification task. Test your architecture on the **Statlog (Vehicle Silhouettes)** Data Set ('Vehicles.csv'). Save your solution as a seperate notebook file with appropriate filename.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "1. Perform the train/validate/test split as 70/15/15.\n",
    "2. Use Random seed as '777' wherever needed.\n",
    "3. Report appropriate measures in addition to accuracy and also plot the confusion matrix.\n",
    "\n",
    "More details on the dataset can be found at: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the data into train, val, test\n",
    "\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' %\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' %\n",
    "                         (stratify_colname))\n",
    "\n",
    "    X = df_input.drop(columns=[stratify_colname])  # Contains all columns.\n",
    "    # Dataframe of just the column on which to stratify.\n",
    "    y = df_input[[stratify_colname]]\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(\n",
    "                                                              1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode each class of column bus with a unique int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "id": "i6Bo1sU2fWVM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>36</th>\n",
       "      <th>73</th>\n",
       "      <th>199</th>\n",
       "      <th>73.1</th>\n",
       "      <th>6</th>\n",
       "      <th>162</th>\n",
       "      <th>40</th>\n",
       "      <th>20</th>\n",
       "      <th>127</th>\n",
       "      <th>189</th>\n",
       "      <th>401</th>\n",
       "      <th>125</th>\n",
       "      <th>72</th>\n",
       "      <th>6.1</th>\n",
       "      <th>19</th>\n",
       "      <th>200</th>\n",
       "      <th>204</th>\n",
       "      <th>bus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>133</td>\n",
       "      <td>166</td>\n",
       "      <td>334</td>\n",
       "      <td>121</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>196</td>\n",
       "      <td>205</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "      <td>148</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>129</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>142</td>\n",
       "      <td>161</td>\n",
       "      <td>249</td>\n",
       "      <td>153</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>194</td>\n",
       "      <td>201</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>134</td>\n",
       "      <td>140</td>\n",
       "      <td>204</td>\n",
       "      <td>148</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>194</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "      <td>95</td>\n",
       "      <td>202</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>193</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>160</td>\n",
       "      <td>220</td>\n",
       "      <td>559</td>\n",
       "      <td>237</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>196</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "      <td>142</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "      <td>168</td>\n",
       "      <td>327</td>\n",
       "      <td>165</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>186</td>\n",
       "      <td>191</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>57</td>\n",
       "      <td>116</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>125</td>\n",
       "      <td>142</td>\n",
       "      <td>229</td>\n",
       "      <td>132</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>178</td>\n",
       "      <td>184</td>\n",
       "      <td>opel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "      <td>107</td>\n",
       "      <td>222</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>218</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>173</td>\n",
       "      <td>232</td>\n",
       "      <td>703</td>\n",
       "      <td>229</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>94</td>\n",
       "      <td>38</td>\n",
       "      <td>84</td>\n",
       "      <td>158</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>169</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>196</td>\n",
       "      <td>430</td>\n",
       "      <td>155</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>190</td>\n",
       "      <td>195</td>\n",
       "      <td>opel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>104</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>191</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>197</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>218</td>\n",
       "      <td>583</td>\n",
       "      <td>234</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>94</td>\n",
       "      <td>48</td>\n",
       "      <td>87</td>\n",
       "      <td>162</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>157</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>179</td>\n",
       "      <td>363</td>\n",
       "      <td>186</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>184</td>\n",
       "      <td>195</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>845 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     100  36   73  199  73.1   6  162  40  20  127  189  401  125  72  6.1  \\\n",
       "0     91  36   72  162    60   8  150  44  19  133  166  334  121  63    2   \n",
       "1     91  41   64  148    61   8  129  51  18  142  161  249  153  68    6   \n",
       "2     86  39   58  125    55   5  117  57  17  134  140  204  148  69    7   \n",
       "3     95  53   95  202    65  10  193  34  22  160  220  559  237  71    3   \n",
       "4     91  43   72  142    56   7  149  45  19  140  168  327  165  72   13   \n",
       "..   ...  ..  ...  ...   ...  ..  ...  ..  ..  ...  ...  ...  ...  ..  ...   \n",
       "840   80  37   57  116    55   6  125  54  18  125  142  229  132  81    8   \n",
       "841  104  55  107  222    68  11  218  31  24  173  232  703  229  71    3   \n",
       "842   94  38   84  158    55   9  169  39  20  130  196  430  155  69    9   \n",
       "843  104  52  100  191    59   9  197  33  23  158  218  583  234  70   10   \n",
       "844   94  48   87  162    64  10  157  43  20  161  179  363  186  75    4   \n",
       "\n",
       "     19  200  204   bus  \n",
       "0    22  196  205  saab  \n",
       "1    12  194  201   van  \n",
       "2     6  190  194   van  \n",
       "3     2  188  196  saab  \n",
       "4    23  186  191  saab  \n",
       "..   ..  ...  ...   ...  \n",
       "840   5  178  184  opel  \n",
       "841  10  188  199  saab  \n",
       "842  15  190  195  opel  \n",
       "843  10  191  198  saab  \n",
       "844  15  184  195   van  \n",
       "\n",
       "[845 rows x 19 columns]"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np.random.seed(777)\n",
    "df = pd.read_csv('..//Data//Vehicles.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode cat variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saab' 'van' 'bus' 'opel']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "840    3\n",
       "841    0\n",
       "842    3\n",
       "843    0\n",
       "844    1\n",
       "Name: bus, Length: 845, dtype: int64"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['bus'].unique())\n",
    "df['bus'] = pd.factorize(df['bus'])[0]\n",
    "df['bus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18, 591), (18, 127), (18, 127), (1, 591), (1, 127), (1, 127))"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_stratified_into_train_val_test(df, stratify_colname='bus',\n",
    "                                                                                      frac_train=0.7, frac_val=0.15, frac_test=0.15,\n",
    "                                                                                      random_state=None)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = X_train.T.to_numpy(), X_val.T.to_numpy(\n",
    "), X_test.T.to_numpy(), y_train.T.to_numpy(), y_val.T.to_numpy(), y_test.T.to_numpy()\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, valx, testx, trainy,valy,testy = X_train.T, X_val.T, X_test.T, y_train.T, y_val.T, y_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_architecture(X, Y):\n",
    "    n_x = X.shape[1]  # size of input layer\n",
    "    n_h = len(np.unique(Y))\n",
    "    n_y = 1\n",
    "    return (n_x, n_h, n_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    W1 = np.random.randn(n_x, n_h) * 0.01\n",
    "    b1 = np.zeros((1, n_h))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1\n",
    "                  }\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    print(x.shape)\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(probs, y):\n",
    "    correct_logprobs = -np.log(probs[range(y.shape[0]),y])\n",
    "    return np.sum(correct_logprobs)/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803238741323343"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  = np.array([[.10,.20,.70], [.10,.60,.30]])\n",
    "y = np.array([2,2])\n",
    "\n",
    "correct_logprobs = -np.log(a[range(y.shape[0]),y])\n",
    "np.sum(correct_logprobs)/y.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, a1=softmax):\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ###\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    ### START CODE HERE ##\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = softmax(Z1)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1}\n",
    "\n",
    "    return A1, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(A1, Y, loss_function=cross_entropy_loss):\n",
    "    # Compute the cross-entropy loss\n",
    "    ### START CODE HERE ###\n",
    "    loss = loss_function(A1, Y)\n",
    "    ### END CODE HERE ###\n",
    "    loss = float(np.squeeze(loss))\n",
    "    assert(isinstance(loss, float))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(parameters, cache, X, Y):\n",
    "\n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    ### START CODE HERE ###\n",
    "    W1 = parameters['W1']\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    ### START CODE HERE ###\n",
    "    A1 = cache['A1']\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2.\n",
    "    ### START CODE HERE ###\n",
    "    dscores = A1\n",
    "    dscores[range(Y.shape[0]),Y] -= 1\n",
    "    dscores /= Y.shape[0]\n",
    "    dW1 = np.dot(X.T, dscores)\n",
    "    db1 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "            }\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(parameters, grads, learning_rate=0.01):\n",
    "\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ###\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ###\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    ## END CODE HERE ###\n",
    "\n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ###\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1\n",
    "    }\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X, Y, n_h, num_iterations=10000, learning_rate=0.01, print_loss=False, a1=softmax, loss_function=cross_entropy_loss):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    n_x = model_architecture(X, Y)[0]\n",
    "    n_y = model_architecture(X, Y)[2]\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A1, cache\".\n",
    "        A1, cache = forward_propagation(X, parameters, a1=a1)\n",
    "        \n",
    "        # loss function. Inputs: \"A2, Y, parameters\". Outputs: \"loss\".\n",
    "        loss = compute_loss(A1, Y, loss_function=loss_function)\n",
    "\n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = backprop(parameters, cache, X, Y)\n",
    "\n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update(parameters, grads)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Print the loss every 100 iterations\n",
    "        if print_loss and i % 100 == 0:\n",
    "            print(\"loss after iteration %i: %f\" % (i, loss))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "\n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    ### START CODE HERE ###\n",
    "    A1, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.argmax(A1.T, axis=1)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 4)\n",
      "(591, 4)\n",
      "(591, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walee\\AppData\\Local\\Temp\\ipykernel_10512\\2972795427.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  exp_scores = np.exp(x)\n",
      "C:\\Users\\walee\\AppData\\Local\\Temp\\ipykernel_10512\\2972795427.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
      "C:\\Users\\walee\\AppData\\Local\\Temp\\ipykernel_10512\\2020298733.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  correct_logprobs = -np.log(probs[range(y.shape[0]),y])\n"
     ]
    }
   ],
   "source": [
    "parameters = NeuralNetwork(trainx, trainy, 4, num_iterations = 3, learning_rate = 0.01, print_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan]]),\n",
       " 'b1': array([[nan, nan, nan, nan]])}"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(parameters, trainx)\n",
    "predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7037ec29b621de18a3396a0455ec45ad55ce896f0aa235683271d94d3867e1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
