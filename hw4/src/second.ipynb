{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the language to English to use spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peace be upon you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>today i present to you another programme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the subject of the study of arabic sign language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>today words are sparse in religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>also ordinary words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no partner of god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>allah is the greatest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "1                                           god name\n",
       "2                                          thank god\n",
       "3                             all deaf hearing arabs\n",
       "4                                  peace be upon you\n",
       "5           today i present to you another programme\n",
       "6   the subject of the study of arabic sign language\n",
       "7                 today words are sparse in religion\n",
       "8                                also ordinary words\n",
       "9                                  no partner of god\n",
       "10                             allah is the greatest"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionlist = {\n",
    "    1: \"god name\",\n",
    "    2: \"thank god\",\n",
    "    3: \"all deaf hearing arabs\",\n",
    "    4: \"peace be upon you\",\n",
    "    5: \"today i present to you another programme\",\n",
    "    6: \"the subject of the study of arabic sign language\",\n",
    "    7: \"today words are sparse in religion\",\n",
    "    8: \"also ordinary words\",\n",
    "    9: \"no partner of god\",\n",
    "    10: \"allah is the greatest\"\n",
    "\n",
    "}\n",
    "\n",
    "captions = pd.DataFrame.from_dict(captionlist, orient='index')\n",
    "# Change the index to be in range 1 - 10\n",
    "captions.index = [i+1 for i in range(10)]\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,\n",
       " 38,\n",
       " {'all',\n",
       "  'allah',\n",
       "  'also',\n",
       "  'another',\n",
       "  'arabic',\n",
       "  'arabs',\n",
       "  'are',\n",
       "  'be',\n",
       "  'deaf',\n",
       "  'god',\n",
       "  'greatest',\n",
       "  'hearing',\n",
       "  'i',\n",
       "  'in',\n",
       "  'is',\n",
       "  'language',\n",
       "  'name',\n",
       "  'no',\n",
       "  'of',\n",
       "  'ordinary',\n",
       "  'partner',\n",
       "  'peace',\n",
       "  'present',\n",
       "  'programme',\n",
       "  'religion',\n",
       "  'sign',\n",
       "  'sparse',\n",
       "  'startdeq',\n",
       "  'stopdeq',\n",
       "  'study',\n",
       "  'subject',\n",
       "  'thank',\n",
       "  'the',\n",
       "  'to',\n",
       "  'today',\n",
       "  'upon',\n",
       "  'words',\n",
       "  'you'})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "START = 'startdeq'\n",
    "STOP = 'stopdeq'\n",
    "MAX_SEQ_LENGTH = len(max(captions[0], key=len).split(\" \")) + 2\n",
    "VOCAB = set(\" \".join(captions[0]).split(\" \")) | {START, STOP}\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "IMG_SIZE = 224\n",
    "EMBEDDING_SHAPE = 300\n",
    "OUTPUT_DIM = 2048\n",
    "MAX_SEQ_LENGTH, VOCAB_SIZE, VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>image_dir</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         video_name  \\\n",
       "0  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "1  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "2  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "3  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "4  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "\n",
       "                                           image_dir                 caption  \n",
       "0  ../data/train/0003/01_0003_(10_03_21_21_04_26)...  all deaf hearing arabs  \n",
       "1  ../data/train/0003/01_0003_(10_03_21_21_04_26)...  all deaf hearing arabs  \n",
       "2  ../data/train/0003/01_0003_(10_03_21_21_04_26)...  all deaf hearing arabs  \n",
       "3  ../data/train/0003/01_0003_(10_03_21_21_04_26)...  all deaf hearing arabs  \n",
       "4  ../data/train/0003/01_0003_(10_03_21_21_04_26)...  all deaf hearing arabs  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "directory = '../data/train'\n",
    "\n",
    "videos = []\n",
    "images_dir = []\n",
    "labels = []\n",
    "df = pd.DataFrame()\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for label in os.listdir(directory):\n",
    "    f1 = os.path.join(directory, label)\n",
    "    for video in os.listdir(f1):\n",
    "        f2 = os.path.join(f1, video)\n",
    "        for frame in os.listdir(f2):\n",
    "            videos.append(f2)\n",
    "            images_dir.append(os.path.join(f2, frame))\n",
    "            labels.append(int(label))\n",
    "\n",
    "df['video_name'] = videos\n",
    "df['image_dir'] = images_dir\n",
    "df['caption'] = labels\n",
    "df['caption'] = df['caption'].apply(lambda x: captions[0][x])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(df['video_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>images</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[../data/train/0003/01_0003_(10_03_21_21_04_26...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_05_28)_c</td>\n",
       "      <td>[../data/train/0003/01_0003_(10_03_21_21_05_28...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_36)_c</td>\n",
       "      <td>[../data/train/0003/01_0003_(10_03_21_21_04_36...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_08_11)_c</td>\n",
       "      <td>[../data/train/0003/01_0003_(10_03_21_21_08_11...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/0003/02_0003_(27_02_21_19_40_00)_c</td>\n",
       "      <td>[../data/train/0003/02_0003_(27_02_21_19_40_00...</td>\n",
       "      <td>all deaf hearing arabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>../data/train/0006/02_0006_(16_02_21_19_09_22)_c</td>\n",
       "      <td>[../data/train/0006/02_0006_(16_02_21_19_09_22...</td>\n",
       "      <td>the subject of the study of arabic sign language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>../data/train/0006/01_0006_(16_02_21_19_33_14)_c</td>\n",
       "      <td>[../data/train/0006/01_0006_(16_02_21_19_33_14...</td>\n",
       "      <td>the subject of the study of arabic sign language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>../data/train/0006/02_0006_(16_02_21_19_10_16)_c</td>\n",
       "      <td>[../data/train/0006/02_0006_(16_02_21_19_10_16...</td>\n",
       "      <td>the subject of the study of arabic sign language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>../data/train/0006/02_0006_(16_02_21_19_05_40)_c</td>\n",
       "      <td>[../data/train/0006/02_0006_(16_02_21_19_05_40...</td>\n",
       "      <td>the subject of the study of arabic sign language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>../data/train/0006/02_0006_(16_02_21_19_07_54)_c</td>\n",
       "      <td>[../data/train/0006/02_0006_(16_02_21_19_07_54...</td>\n",
       "      <td>the subject of the study of arabic sign language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           video_name  \\\n",
       "0    ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "1    ../data/train/0003/01_0003_(10_03_21_21_05_28)_c   \n",
       "2    ../data/train/0003/01_0003_(10_03_21_21_04_36)_c   \n",
       "3    ../data/train/0003/01_0003_(10_03_21_21_08_11)_c   \n",
       "4    ../data/train/0003/02_0003_(27_02_21_19_40_00)_c   \n",
       "..                                                ...   \n",
       "529  ../data/train/0006/02_0006_(16_02_21_19_09_22)_c   \n",
       "530  ../data/train/0006/01_0006_(16_02_21_19_33_14)_c   \n",
       "531  ../data/train/0006/02_0006_(16_02_21_19_10_16)_c   \n",
       "532  ../data/train/0006/02_0006_(16_02_21_19_05_40)_c   \n",
       "533  ../data/train/0006/02_0006_(16_02_21_19_07_54)_c   \n",
       "\n",
       "                                                images  \\\n",
       "0    [../data/train/0003/01_0003_(10_03_21_21_04_26...   \n",
       "1    [../data/train/0003/01_0003_(10_03_21_21_05_28...   \n",
       "2    [../data/train/0003/01_0003_(10_03_21_21_04_36...   \n",
       "3    [../data/train/0003/01_0003_(10_03_21_21_08_11...   \n",
       "4    [../data/train/0003/02_0003_(27_02_21_19_40_00...   \n",
       "..                                                 ...   \n",
       "529  [../data/train/0006/02_0006_(16_02_21_19_09_22...   \n",
       "530  [../data/train/0006/01_0006_(16_02_21_19_33_14...   \n",
       "531  [../data/train/0006/02_0006_(16_02_21_19_10_16...   \n",
       "532  [../data/train/0006/02_0006_(16_02_21_19_05_40...   \n",
       "533  [../data/train/0006/02_0006_(16_02_21_19_07_54...   \n",
       "\n",
       "                                             captions  \n",
       "0                              all deaf hearing arabs  \n",
       "1                              all deaf hearing arabs  \n",
       "2                              all deaf hearing arabs  \n",
       "3                              all deaf hearing arabs  \n",
       "4                              all deaf hearing arabs  \n",
       "..                                                ...  \n",
       "529  the subject of the study of arabic sign language  \n",
       "530  the subject of the study of arabic sign language  \n",
       "531  the subject of the study of arabic sign language  \n",
       "532  the subject of the study of arabic sign language  \n",
       "533  the subject of the study of arabic sign language  \n",
       "\n",
       "[534 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos = pd.DataFrame()\n",
    "videos = df['video_name'].unique()\n",
    "df_videos = pd.DataFrame(videos, columns=['video_name'])\n",
    "df_videos['images'] = df_videos['video_name'].apply(lambda x: df[df['video_name'] == x]['image_dir'].values)\n",
    "df_videos['captions'] = df_videos['video_name'].apply(lambda x: df[df['video_name'] == x]['caption'].values[0])\n",
    "df_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build CNN to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "def build_feature_extractor():\n",
    "    InceptionV3_model = applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3), )\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input(inputs)\n",
    "    outputs = InceptionV3_model(preprocess_input)\n",
    "    myModel = keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "    return myModel\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_reader(img_paths):\n",
    "    images = []\n",
    "    for path in img_paths:\n",
    "        image = plt.imread(path)\n",
    "        image = resize_image(image)\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def resize_image(image):\n",
    "    \"\"\"\n",
    "    Resize images to a desired shape, does not account for aspect ratio \n",
    "    \"\"\"\n",
    "    _,_,depth = image.shape\n",
    "    return np.resize(image, (IMG_SIZE, IMG_SIZE, depth))\n",
    "\n",
    "    \n",
    "def encode_video(video_images):\n",
    "    \"\"\"\n",
    "    Takes a video and encode all its frames and return the encoded frames and the captions\n",
    "    The backbone of the generator as it allows dynamic reading of the data\n",
    "    \"\"\"\n",
    "    videoFeatures = []\n",
    "    frames = image_reader(video_images)\n",
    "    features = feature_extractor.predict(frames, verbose=0)\n",
    "    videoFeatures.append(features.squeeze())\n",
    "    return np.squeeze(np.array(videoFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded = pd.DataFrame()\n",
    "# encodings, captions = [], []\n",
    "# for index, row in df_videos.iterrows():\n",
    "#     encoding = encode_video(row['images'])\n",
    "#     encodings.append(encoding)\n",
    "#     captions.append(row['captions'])\n",
    "\n",
    "# df_encoded['video'] = df_videos['video_name']\n",
    "# df_encoded['encoding'] = encodings\n",
    "# df_encoded['caption'] = captions\n",
    "# df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.to_pickle('../data/encoded_train.pkl')\n",
    "df_encoded = pd.read_pickle('../data/encoded_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>encoding</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>startdeq all deaf hearing arabs stopdeq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_05_28)_c</td>\n",
       "      <td>[[0.08136222, 0.055209946, 0.40456566, 0.13459...</td>\n",
       "      <td>startdeq all deaf hearing arabs stopdeq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_36)_c</td>\n",
       "      <td>[[0.0, 0.038305435, 0.13834573, 0.17418434, 0....</td>\n",
       "      <td>startdeq all deaf hearing arabs stopdeq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_08_11)_c</td>\n",
       "      <td>[[0.014240551, 0.14180474, 0.3848084, 0.298231...</td>\n",
       "      <td>startdeq all deaf hearing arabs stopdeq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/0003/02_0003_(27_02_21_19_40_00)_c</td>\n",
       "      <td>[[0.054453805, 0.31206432, 0.49797043, 0.08702...</td>\n",
       "      <td>startdeq all deaf hearing arabs stopdeq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video  \\\n",
       "0  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "1  ../data/train/0003/01_0003_(10_03_21_21_05_28)_c   \n",
       "2  ../data/train/0003/01_0003_(10_03_21_21_04_36)_c   \n",
       "3  ../data/train/0003/01_0003_(10_03_21_21_08_11)_c   \n",
       "4  ../data/train/0003/02_0003_(27_02_21_19_40_00)_c   \n",
       "\n",
       "                                            encoding  \\\n",
       "0  [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "1  [[0.08136222, 0.055209946, 0.40456566, 0.13459...   \n",
       "2  [[0.0, 0.038305435, 0.13834573, 0.17418434, 0....   \n",
       "3  [[0.014240551, 0.14180474, 0.3848084, 0.298231...   \n",
       "4  [[0.054453805, 0.31206432, 0.49797043, 0.08702...   \n",
       "\n",
       "                                   caption  \n",
       "0  startdeq all deaf hearing arabs stopdeq  \n",
       "1  startdeq all deaf hearing arabs stopdeq  \n",
       "2  startdeq all deaf hearing arabs stopdeq  \n",
       "3  startdeq all deaf hearing arabs stopdeq  \n",
       "4  startdeq all deaf hearing arabs stopdeq  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded['caption'] = df_encoded['caption'].apply(lambda x: START + ' ' + x + ' ' + STOP)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def tokenize(sentences):\n",
    "    # Create tokenizer\n",
    "    text_tokenizer = Tokenizer()\n",
    "    # Fit texts\n",
    "    text_tokenizer.fit_on_texts(sentences)\n",
    "    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2048)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_tokenized, tokenizer = tokenize(df_encoded['caption'])\n",
    "df_encoded['caption_tokenized'] = captions_tokenized\n",
    "df_encoded.head()\n",
    "df_encoded['encoding'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = max([len(caption) for caption in captions_tokenized])\n",
    "# df_encoded['caption_tokenized_padded'] = df_encoded['caption_tokenized'].apply(lambda x: keras.utils.pad_sequences([x], maxlen=max_length, padding='post')[0])\n",
    "# df_encoded['caption_tokenized_padded'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.to_pickle('../data/encoded_train_final.pkl')\n",
    "def generate_training_samples(row):\n",
    "    \"\"\"\n",
    "    Takes a row of the encoded dataframe and generates the training samples\n",
    "    \"\"\"\n",
    "    # Get the caption\n",
    "    caption = row['caption_tokenized']\n",
    "    # Get the encoding\n",
    "    encoding = row['encoding']\n",
    "    # Get the video name\n",
    "    video_name = row['video']\n",
    "    # Get the length of the caption\n",
    "    caption_length = len(caption)\n",
    "    # Get the number of samples\n",
    "    inputs =[]\n",
    "    outputs = []\n",
    "    videos = []\n",
    "    encodings = []\n",
    "    \n",
    "    for i in range(1, caption_length):\n",
    "        videos.append(video_name)\n",
    "        encodings.append(encoding)\n",
    "        inputs.append(caption[:i])\n",
    "        outputs.append(caption[i])\n",
    "    return pd.DataFrame({'video': videos, 'encodings': encodings, 'input': inputs, 'output': outputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>encodings</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29]</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31, 32]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video  \\\n",
       "0  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "1  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "2  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "3  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "4  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "\n",
       "                                           encodings                input  \\\n",
       "0  [[0.10615034, 0.07749777, 0.15894692, 0.015735...                  [1]   \n",
       "1  [[0.10615034, 0.07749777, 0.15894692, 0.015735...              [1, 29]   \n",
       "2  [[0.10615034, 0.07749777, 0.15894692, 0.015735...          [1, 29, 30]   \n",
       "3  [[0.10615034, 0.07749777, 0.15894692, 0.015735...      [1, 29, 30, 31]   \n",
       "4  [[0.10615034, 0.07749777, 0.15894692, 0.015735...  [1, 29, 30, 31, 32]   \n",
       "\n",
       "   output  \n",
       "0      29  \n",
       "1      30  \n",
       "2      31  \n",
       "3      32  \n",
       "4       2  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_training_samples(df_encoded.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>encodings</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29]</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31, 32]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video  \\\n",
       "0  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "1  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "2  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "3  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "4  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "\n",
       "                                           encodings                input  \\\n",
       "0  [[0.10615034, 0.07749777, 0.15894692, 0.015735...                  [1]   \n",
       "1  [[0.10615034, 0.07749777, 0.15894692, 0.015735...              [1, 29]   \n",
       "2  [[0.10615034, 0.07749777, 0.15894692, 0.015735...          [1, 29, 30]   \n",
       "3  [[0.10615034, 0.07749777, 0.15894692, 0.015735...      [1, 29, 30, 31]   \n",
       "4  [[0.10615034, 0.07749777, 0.15894692, 0.015735...  [1, 29, 30, 31, 32]   \n",
       "\n",
       "   output  \n",
       "0      29  \n",
       "1      30  \n",
       "2      31  \n",
       "3      32  \n",
       "4       2  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = pd.DataFrame()\n",
    "for index, row in df_encoded.iterrows():\n",
    "    df_training = pd.concat([df_training, generate_training_samples(row)])\n",
    "\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_training.to_pickle('../data/training_samples_no_padding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>encodings</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/0003/01_0003_(10_03_21_21_04_26)_c</td>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31, 32, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video  \\\n",
       "0  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "1  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "2  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "3  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "4  ../data/train/0003/01_0003_(10_03_21_21_04_26)_c   \n",
       "\n",
       "                                           encodings  \\\n",
       "0  [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "1  [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "2  [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "3  [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "4  [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "\n",
       "                                   input  \\\n",
       "0      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1     [1, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2    [1, 29, 30, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3   [1, 29, 30, 31, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [1, 29, 30, 31, 32, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                              output  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['input'] = df_training['input'].apply(lambda x: keras.utils.pad_sequences([x], maxlen=11, padding='post')[0])\n",
    "df_training['output'] = df_training['output'].apply(lambda x: keras.utils.to_categorical(x, num_classes=len(tokenizer.word_index) + 1))\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_training.to_pickle('../data/training_samples_padded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encodings</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.10615034, 0.07749777, 0.15894692, 0.015735...</td>\n",
       "      <td>[1, 29, 30, 31, 32, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[0.071131654, 0.07954844, 0.28291216, 0.15527...</td>\n",
       "      <td>[1, 3, 24, 5, 3, 25, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[0.071131654, 0.07954844, 0.28291216, 0.15527...</td>\n",
       "      <td>[1, 3, 24, 5, 3, 25, 5, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[0.071131654, 0.07954844, 0.28291216, 0.15527...</td>\n",
       "      <td>[1, 3, 24, 5, 3, 25, 5, 26, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[0.071131654, 0.07954844, 0.28291216, 0.15527...</td>\n",
       "      <td>[1, 3, 24, 5, 3, 25, 5, 26, 27, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[0.071131654, 0.07954844, 0.28291216, 0.15527...</td>\n",
       "      <td>[1, 3, 24, 5, 3, 25, 5, 26, 27, 28, 0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            encodings  \\\n",
       "0   [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "1   [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "2   [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "3   [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "4   [[0.10615034, 0.07749777, 0.15894692, 0.015735...   \n",
       "..                                                ...   \n",
       "5   [[0.071131654, 0.07954844, 0.28291216, 0.15527...   \n",
       "6   [[0.071131654, 0.07954844, 0.28291216, 0.15527...   \n",
       "7   [[0.071131654, 0.07954844, 0.28291216, 0.15527...   \n",
       "8   [[0.071131654, 0.07954844, 0.28291216, 0.15527...   \n",
       "9   [[0.071131654, 0.07954844, 0.28291216, 0.15527...   \n",
       "\n",
       "                                     input  \\\n",
       "0        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1       [1, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2      [1, 29, 30, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3     [1, 29, 30, 31, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4    [1, 29, 30, 31, 32, 0, 0, 0, 0, 0, 0]   \n",
       "..                                     ...   \n",
       "5      [1, 3, 24, 5, 3, 25, 0, 0, 0, 0, 0]   \n",
       "6      [1, 3, 24, 5, 3, 25, 5, 0, 0, 0, 0]   \n",
       "7     [1, 3, 24, 5, 3, 25, 5, 26, 0, 0, 0]   \n",
       "8    [1, 3, 24, 5, 3, 25, 5, 26, 27, 0, 0]   \n",
       "9   [1, 3, 24, 5, 3, 25, 5, 26, 27, 28, 0]   \n",
       "\n",
       "                                               output  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "..                                                ...  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[2977 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fit2 = df_training[['encodings', 'input', 'output']].copy()\n",
    "df_fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combined_inputs = [[i,j] for i,j in zip( df_training['encodings'].values,df_training['input'].values)]\n",
    "# df_fit = pd.DataFrame({'input': combined_inputs, 'output': df_training['output'].to_numpy()})\n",
    "# df_fit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE+1, EMBEDDING_SHAPE))\n",
    "\n",
    "for word in VOCAB:\n",
    "    index = tokenizer.word_index[word]\n",
    "    embedding_matrix[index] = nlp(word).vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_generator(df, batch_size):\n",
    "#   # x1 - Training data for df\n",
    "#   # x2 - The caption that goes with each photo\n",
    "#   # y - The predicted rest of the caption\n",
    "#   x1, x2, y = [], [], []\n",
    "#   n=0\n",
    "#   videos = np.unique(df['video_name']).tolist()\n",
    "#   x1, x2, y = [],[], []\n",
    "#   while True:\n",
    "#     n+=1\n",
    "#     x1.append(df.iloc[n-1]['encodings'])\n",
    "#     x2.append(df.iloc[n-1]['input'])\n",
    "#     y.append(df.iloc[n-1]['outpus'])\n",
    "#     if n%batch_size == 0:\n",
    "#         yield ([np.array(x1), np.array(x2)], np.array(y))\n",
    "#         x1, x2,y = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 80, 2048)]   0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 11, 300)      11400       ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, 32),         266368      ['input_11[0][0]']               \n",
      "                                 (None, 32),                                                      \n",
      "                                 (None, 32)]                                                      \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 32)           42624       ['embedding_2[0][0]',            \n",
      "                                                                  'lstm_4[0][1]',                 \n",
      "                                                                  'lstm_4[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 39)           1287        ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 321,679\n",
      "Trainable params: 321,679\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Embedding, add\n",
    "\n",
    "inputs1 = keras.Input(shape=(80, OUTPUT_DIM))\n",
    "# fe1 = Dropout(0.5)(inputs1)\n",
    "_,state_h, state_c = LSTM(32, activation='relu', return_state=True)(inputs1)\n",
    "\n",
    "\n",
    "inputs2 = keras.Input(shape=(MAX_SEQ_LENGTH,))\n",
    "se1 = Embedding(VOCAB_SIZE, EMBEDDING_SHAPE, mask_zero=True)(inputs2)\n",
    "# se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(32)(se1,  initial_state =[state_h, state_c])\n",
    "outputs = Dense(VOCAB_SIZE+1, activation='softmax')(se3)\n",
    "caption_model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "# caption_model.layers[2].set_weights([embedding_matrix])\n",
    "# caption_model.layers[2].trainable = False\n",
    "adamOptimizer = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer=adamOptimizer, metrics=['accuracy'])\n",
    "caption_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_numpy(input_list):\n",
    "#   # Initialize an empty list for storing the converted arrays\n",
    "#   output_arrays = []\n",
    "  \n",
    "#   # Loop through the elements of the input list\n",
    "#   for element in input_list:\n",
    "#     # If the element is a list, recursively convert it to a NumPy array\n",
    "#     if isinstance(element, list):\n",
    "#       element = convert_to_numpy(element)\n",
    "\n",
    "#     # Convert the element to a NumPy array\n",
    "#     element = np.array(element)\n",
    "\n",
    "#     # Append the element to the list of output arrays\n",
    "#     output_arrays.append(element)\n",
    "\n",
    "#   # Return the list of output arrays\n",
    "#   return output_arrays\n",
    "\n",
    "# df_fit['input'] = df_fit['input'].apply(lambda x: convert_to_numpy(x))\n",
    "# df_fit['output'] = df_fit['output'].apply(lambda x: convert_to_numpy(x))\n",
    "\n",
    "data = df_fit2.to_numpy()\n",
    "data0 = tf.convert_to_tensor(data[:,0].tolist())\n",
    "data2 = tf.convert_to_tensor(data[:,1].tolist())\n",
    "data3 = tf.convert_to_tensor(data[:,2].tolist())\n",
    "# data = data.tolist()\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "# get the first axis of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class MyDataset(tf.data.Dataset):\n",
    "#   def __init__(self, data):\n",
    "#     self.data = data\n",
    "\n",
    "#   def __len__(self):\n",
    "#     # Return the length of the dataset\n",
    "#     return len(self.data)\n",
    "\n",
    "#   def __getitem__(self, index):\n",
    "#     # Return the data item at the specified index\n",
    "#     i,j,k = self.data[index]\n",
    "#     print(i,j,k)\n",
    "#     return [i,j], k\n",
    "\n",
    "# dataset = MyDataset.zip((dataset1, dataset2, dataset3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 23:31:39.976750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-06 23:31:41.436421: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2022-12-06 23:31:41.446042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-06 23:31:44.843481: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/94 [=============>................] - ETA: 4:19 - loss: 3.6518 - accuracy: 0.1012"
     ]
    }
   ],
   "source": [
    "caption_model.fit(x=[data0, data2], y = data3, epochs=1, batch_size= 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
